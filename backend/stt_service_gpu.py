"""
GPU-Accelerated Speech-to-Text Service
Faster-Whisper ile CUDA destekli hÄ±zlÄ± transkripsiyon
"""

# âš ï¸ KRÄ°TÄ°K: CUDA/cuDNN ortamÄ±nÄ± hazÄ±rla - TÃœM import'lardan Ã–NCE!
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# 1) PATH ayarlarÄ±
import cuda_setup

# 2) DLL'leri Ã¶nceden yÃ¼kle
import cudnn_preload

import warnings

# cuDNN / CUDA ile ilgili uyarÄ±larÄ± kÄ±s
warnings.filterwarnings("ignore", category=UserWarning)

# CUDA modÃ¼llerini lazy yÃ¼kle (Whisper/Faster-Whisper Ã¶nerisi)
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "3")
os.environ.setdefault("CUDA_MODULE_LOADING", "LAZY")


# ==================================================
# KÃœTÃœPHANE Ä°THALATLARI (DLL yollarÄ± ayarlandÄ±ktan sonra)
# ==================================================
import time
import logging
import numpy as np
from faster_whisper import WhisperModel
import io
import wave

# ==========================================
# GPU HIZ OPTÄ°MÄ°ZASYONU AYARLARI
# ==========================================

# FFmpeg yolu (Windows iÃ§in sabit path)
FFMPEG_PATH = r"C:\Users\hamdi\Downloads\ffmpeg-8.0-full_build\ffmpeg-8.0-full_build\bin\ffmpeg.exe"

# Model Boyutu: 'tiny', 'base', 'small', 'medium', 'large-v2', 'large-v3'
# TÃ¼rkÃ§e iÃ§in en iyi: large-v3 (en aÄŸÄ±r ama maksimum doÄŸruluk)
MODEL_SIZE = "large-v3"

# Hesaplama Tipi: RTX serisi iÃ§in "float16", eski kartlar iÃ§in "int8"
# cuDNN hatasÄ± varsa "int8" kullan (yine de GPU hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r)
COMPUTE_TYPE = "int8"  # Genel amaÃ§lÄ± compute tipi (bilgi amaÃ§lÄ±)

# Daha ince ayar iÃ§in ayrÄ± GPU/CPU compute tipleri
GPU_COMPUTE_TYPE = "float16"  # GPU'da daha doÄŸal ve doÄŸru sonuÃ§lar
CPU_COMPUTE_TYPE = "int8"     # CPU fallback iÃ§in hafif ve hÄ±zlÄ±

# Cihaz: GPU iÃ§in "cuda", CPU iÃ§in "cpu"
DEVICE = "cuda"

class GPUWhisperSTT:
    """GPU hÄ±zlandÄ±rmalÄ± Whisper STT servisi"""
    
    def __init__(self):
        """Faster-Whisper modelini GPU ile yÃ¼kle"""
        self.model = None
        self._load_model()
    
    def _load_model(self):
        """Modeli yÃ¼kle - Ã¶nce kalite, sonra hÄ±z odaklÄ± fallback ile."""

        # 1) Tercih: GPU + float16 (RTX 4050 iÃ§in ideal)
        try:
            logging.info(f"ğŸš€ Model yÃ¼kleniyor: CUDA - {GPU_COMPUTE_TYPE} ({MODEL_SIZE})...")
            
            self.model = WhisperModel(
                MODEL_SIZE, 
                device="cuda", 
                compute_type=GPU_COMPUTE_TYPE,
                num_workers=2,
                cpu_threads=4,
                download_root=None
            )
            
            logging.info(f"âœ… Model baÅŸarÄ±yla yÃ¼klendi: CUDA ({MODEL_SIZE}/{GPU_COMPUTE_TYPE})")
            return
            
        except Exception as e:
            logging.warning(f"âš ï¸ CUDA/{GPU_COMPUTE_TYPE} yÃ¼klenemedi: {str(e)[:120]}")
            logging.info("ğŸ”„ CPU moduna geÃ§iliyor...")
            
            try:
                self.model = WhisperModel(
                    MODEL_SIZE, 
                    device="cpu", 
                    compute_type=CPU_COMPUTE_TYPE,
                    num_workers=2,
                    download_root=None
                )
                logging.info(f"âœ… Model baÅŸarÄ±yla yÃ¼klendi: CPU ({MODEL_SIZE}/{CPU_COMPUTE_TYPE})")
                return
            except Exception as e2:
                raise RuntimeError(f"âŒ Model yÃ¼klenemedi: {str(e2)}")
    
    def transcribe_audio_bytes(self, audio_bytes: bytes, language: str = "tr") -> tuple:
        """
        Ses verisini metne Ã§evir (GPU hÄ±zlandÄ±rmalÄ±)
        
        Args:
            audio_bytes: WebM/WAV/MP3 formatÄ±nda ses verisi
            language: Dil kodu (varsayÄ±lan: "tr")
            
        Returns:
            tuple: (metin, iÅŸlem sÃ¼resi)
        """
        if not self.model:
            raise RuntimeError("Whisper modeli yÃ¼klenmemiÅŸ!")
        
        start_time = time.time()
        
        try:
            # WebM â†’ WAV dÃ¶nÃ¼ÅŸÃ¼mÃ¼ (tarayÄ±cÄ±dan gelen ses kalitesini iyileÅŸtir)
            import tempfile
            import subprocess
            
            with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as temp_input:
                temp_input.write(audio_bytes)
                temp_input_path = temp_input.name
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_output:
                temp_output_path = temp_output.name
            
            try:
                # FFmpeg ile yÃ¼ksek kaliteli WAV'a Ã§evir
                subprocess.run([
                    FFMPEG_PATH, "-y", "-i", temp_input_path,
                    "-ar", "16000",  # 16kHz sampling rate (Whisper iÃ§in optimal)
                    "-ac", "1",       # Mono
                    "-c:a", "pcm_s16le",  # 16-bit PCM
                    temp_output_path
                ], check=True, capture_output=True)
                
                # DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ WAV'Ä± oku
                with open(temp_output_path, "rb") as f:
                    audio_file = io.BytesIO(f.read())
            finally:
                # GeÃ§ici dosyalarÄ± temizle
                try:
                    os.unlink(temp_input_path)
                    os.unlink(temp_output_path)
                except:
                    pass
            
            # --- MAKSIMUM KALÄ°TE TRANSKRÄ°PSÄ°YON (TÃ¼rkÃ§e optimizasyonu) ---
            segments, info = self.model.transcribe(
                audio_file,
                language=language,      # TÃ¼rkÃ§e sabit,

                beam_size=5,            # Beam search: en iyi 5 yolu tara
                best_of=5,              # Her segment iÃ§in 5 deneme, en iyisini seÃ§
                temperature=0.0,        # Deterministik Ã§Ä±ktÄ±
                patience=2.0,           # Daha sabÄ±rlÄ± decode (kalite iÃ§in)
                length_penalty=1.0,     # Uzun cÃ¼mleleri penalize etme
                repetition_penalty=1.1, # Tekrar eden kelimeleri hafifÃ§e engelleyip
                vad_filter=True,        # Sessiz kÄ±sÄ±mlarÄ± atla
                vad_parameters=dict(
                    min_silence_duration_ms=700,  # CÃ¼mle sonunu daha iyi yakala
                    threshold=0.5,
                    min_speech_duration_ms=250
                ),
                condition_on_previous_text=True,  # Ã–nceki baÄŸlamÄ± kullan (cÃ¼mle tutarlÄ±lÄ±ÄŸÄ±)
                initial_prompt="Merhaba, randevu almak istiyorum. YarÄ±n iÃ§in mÃ¼sait misiniz?",  # TÃ¼rkÃ§e kontext
                no_speech_threshold=0.6,
                log_prob_threshold=-1.0,
                compression_ratio_threshold=2.4
            )
            
            # Segmentleri birleÅŸtir
            text = " ".join([segment.text.strip() for segment in segments])
            
            end_time = time.time()
            process_time = end_time - start_time
            
            # DetaylÄ± log
            logging.info(f"ğŸ¤ STT: '{text[:50]}...' ({process_time:.2f}s - {info.language})")
            
            return text.strip(), process_time
            
        except Exception as e:
            logging.error(f"âŒ Transkripsiyon hatasÄ±: {e}")
            raise
    
    def transcribe_audio_file(self, file_path: str, language: str = "tr") -> tuple:
        """
        Dosyadan ses Ã§evir
        
        Args:
            file_path: Ses dosyasÄ± yolu
            language: Dil kodu
            
        Returns:
            tuple: (metin, iÅŸlem sÃ¼resi)
        """
        start_time = time.time()
        
        try:
            segments, info = self.model.transcribe(
                file_path,
                language=language,
                beam_size=1,
                vad_filter=True,
                temperature=0.0,
                condition_on_previous_text=False
            )
            
            text = " ".join([segment.text.strip() for segment in segments])
            process_time = time.time() - start_time
            
            logging.info(f"ğŸ¤ STT (dosya): '{text[:50]}...' ({process_time:.2f}s)")
            
            return text.strip(), process_time
            
        except Exception as e:
            logging.error(f"âŒ Dosya transkripsiyon hatasÄ±: {e}")
            raise


# Global STT instance (singleton pattern - lazy load)
_stt_service = None

def get_stt_service() -> GPUWhisperSTT:
    """STT service'i al (singleton)"""
    global _stt_service
    if _stt_service is None:
        _stt_service = GPUWhisperSTT()
    return _stt_service


# Test fonksiyonu
if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    print("=" * 60)
    print("ğŸ¤ GPU Whisper STT Servisi Test")
    print("=" * 60)
    
    stt = get_stt_service()
    
    print("\nâœ… STT servisi hazÄ±r ve kullanÄ±ma aÃ§Ä±k!")
    print(f"   ğŸ“Š Model Bilgileri:")
    print(f"   - Model: {MODEL_SIZE}")
    print(f"   - Cihaz: {DEVICE}")
    print(f"   - Compute: {COMPUTE_TYPE}")
    print("\nğŸ’¡ KullanÄ±m:")
    print("   from stt_service_gpu import get_stt_service")
    print("   stt = get_stt_service()")
    print("   text, duration = stt.transcribe_audio_bytes(audio_bytes)")
    print("\nğŸ™ï¸  Mikrofon testi iÃ§in: python test_gpu_stt.py")
    print("=" * 60)
