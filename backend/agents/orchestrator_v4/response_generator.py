"""
Response Generator - LLM Call #2
Tool sonuÃ§larÄ±nÄ± natural Turkish response'a Ã§evir
Temperature: 0.7 (Natural but consistent)
"""

import google.generativeai as genai
import logging
import json
from typing import Dict, Any, Optional


class ResponseGenerator:
    """
    LLM Call #2: Tool result â†’ Natural language response

    GÃ¶revler:
    1. Tool sonuÃ§larÄ±nÄ± yorumla
    2. Context-aware yanÄ±t Ã¼ret (customer name, campaigns)
    3. DoÄŸal, sÄ±cak, profesyonel ton
    4. KÄ±sa ve Ã¶z (max 2-3 cÃ¼mle)
    5. Emoji yok!

    KullanÄ±lan: Gemini text generation (NO function calling)
    """

    def __init__(self, gemini_model: genai.GenerativeModel):
        """
        Args:
            gemini_model: Gemini model instance
        """
        self.model = gemini_model
        self.logger = logging.getLogger(__name__)

    async def generate(
        self,
        action: Dict[str, Any],
        tool_result: Optional[Dict[str, Any]],
        context: Dict[str, Any]
    ) -> str:
        """
        Tool result ve action'a gÃ¶re natural response Ã¼ret.

        Args:
            action: FlowManager'dan gelen action
            tool_result: Tool execution sonucu (None olabilir)
            context: KonuÅŸma context'i (customer_name, campaigns, vb.)

        Returns:
            Natural Turkish response string
        """
        self.logger.info(f"ğŸ’¬ [LLM #2] Response generation baÅŸladÄ±")

        action_type = action.get("action")

        # EÄŸer action "ask_missing" veya "confirm" ise, LLM'e gitmeye gerek yok
        # FlowManager zaten message hazÄ±rlamÄ±ÅŸ
        if action_type in ["ask_missing", "confirm", "ask_alternative"]:
            response = action.get("message", "AnlayamadÄ±m, tekrar eder misiniz?")
            self.logger.info(f"âœ… [LLM #2] Direct message (no LLM): {response[:50]}...")
            return response

        # EÄŸer tool result varsa, LLM ile yorumla
        if tool_result and action_type == "tool_call":
            return await self._generate_tool_response(
                tool_name=action.get("tool"),
                tool_result=tool_result,
                context=context
            )

        # Chat mode - genel sohbet
        if action_type == "chat":
            return "BaÅŸka bir konuda yardÄ±mcÄ± olabilir miyim?"

        # Fallback
        return "AnlayamadÄ±m, tekrar eder misiniz?"

    async def _generate_tool_response(
        self,
        tool_name: str,
        tool_result: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """
        Tool sonucunu LLM ile natural language'e Ã§evir.

        Args:
            tool_name: Ã‡aÄŸrÄ±lan tool'un adÄ±
            tool_result: Tool'dan dÃ¶nen sonuÃ§
            context: Customer name, campaigns, vb.

        Returns:
            Natural Turkish response
        """
        # Context'ten bilgileri al
        customer_name = context.get("customer_name", "MÃ¼ÅŸteri")
        active_campaigns = context.get("active_campaigns", [])

        # Prompt oluÅŸtur - COMPACT
        prompt = self._build_response_prompt(
            tool_name=tool_name,
            tool_result=tool_result,
            customer_name=customer_name,
            active_campaigns=active_campaigns
        )

        try:
            # Gemini'ye gÃ¶nder (text generation, temperature=0.7)
            response = self.model.generate_content(prompt)
            response_text = response.text.strip()

            # Validation - JSON dÃ¶ndÃ¼rmÃ¼ÅŸ mÃ¼? (hata)
            if response_text.startswith("{") or response_text.startswith("["):
                self.logger.warning("âš ï¸ [LLM #2] LLM returned JSON instead of text")
                # JSON parse et ve iÃ§inden text'i Ã§Ä±kar
                try:
                    parsed = json.loads(response_text)
                    if isinstance(parsed, dict):
                        response_text = parsed.get("response", parsed.get("message", response_text))
                except:
                    pass

            # Max length check (300 karakter yeterli)
            if len(response_text) > 300:
                self.logger.warning(f"âš ï¸ [LLM #2] Response too long ({len(response_text)} chars)")
                response_text = response_text[:300] + "..."

            self.logger.info(f"âœ… [LLM #2] Generated response: {response_text[:50]}...")
            return response_text

        except Exception as e:
            self.logger.error(f"âŒ [LLM #2] Generation error: {e}", exc_info=True)
            # Fallback - tool success/failure'a gÃ¶re generic message
            if tool_result.get("success"):
                return "Ä°ÅŸleminizi tamamladÄ±m."
            else:
                return "ÃœzgÃ¼nÃ¼m, bir sorun oluÅŸtu. LÃ¼tfen tekrar deneyin."

    def _build_response_prompt(
        self,
        tool_name: str,
        tool_result: Dict[str, Any],
        customer_name: str,
        active_campaigns: list
    ) -> str:
        """
        Response generation iÃ§in compact prompt.

        Stratejiler:
        - Tool-specific rules
        - Examples vermiyoruz (model iyi)
        - Max 30 satÄ±r
        """
        # Tool result'Ä± formatla (pretty print)
        tool_result_str = json.dumps(tool_result, ensure_ascii=False, indent=2)

        # Kampanya bilgisi (varsa)
        campaign_str = ""
        if active_campaigns:
            campaign_str = "\n### AKTÄ°F KAMPANYALAR ###\n"
            for c in active_campaigns[:2]:  # Max 2 kampanya
                campaign_str += f"- {c.get('name')}: %{c.get('discount')} indirim\n"

        prompt = f"""### GÃ–REV ###
Tool sonucunu doÄŸal TÃ¼rkÃ§e yanÄ±ta Ã§evir.

### BAÄLAM ###
MÃ¼ÅŸteri AdÄ±: {customer_name}
{campaign_str}
### TOOL SONUCU ###
Tool: {tool_name}
Result:
{tool_result_str}

### YANIT KURALLARI ###
1. **Randevu OluÅŸturuldu**: 'success': true ve 'code' varsa â†’ "Randevunuz oluÅŸturuldu. Kod: [CODE]. Sizi bekliyoruz!"
2. **Randevu Sorgu**:
   - Appointments boÅŸ â†’ "KayÄ±tlÄ± randevunuz bulunmuyor."
   - Appointments var, status='confirmed' â†’ Tarih,1 saat, hizmet, uzman listele. Ä°PTAL edilmiÅŸ olanlarÄ± GÃ–STERME!
   - ASLA "iptal edilmiÅŸ" veya "cancelled" deme confirmed randevular iÃ§in!
3. **Alternatif Saatler**: Max 3 seÃ§enek, kÄ±sa liste. "5 AralÄ±k: 09:00, 11:30, 14:00 mÃ¼sait. Hangisi uygun?"
4. **MÃ¼saitlik**: Slots varsa kÄ±saca listele. "Sabah 09:00 ve 10:30 mÃ¼sait."
5. **Uzmanlar**: "Åu uzmanlarÄ±mÄ±z hizmet veriyor: [Ä°simler]. Hangisini tercih edersiniz?"
6. **Kampanyalar**: Varsa kÄ±saca bahset. "{customer_name} Bey/HanÄ±m, %20 indirim kampanyamÄ±z var."
7. **Hata**: 'success': false â†’ Ã–zÃ¼r dile, alternatif Ã¶ner veya eksik bilgi sor.
8. **Ton**: SÄ±cak, profesyonel. MÃ¼ÅŸteri adÄ±nÄ± kullan ("{customer_name} Bey/HanÄ±m").
9. **Uzunluk**: Max 2-3 cÃ¼mle. KÄ±sa ve Ã¶z.
10. **EMOJÄ° YOK**: HiÃ§ emoji kullanma!

### Ã‡IKTI ###
Sadece doÄŸal TÃ¼rkÃ§e yanÄ±t yaz. JSON, kod, markup YOK!
"""
        return prompt


# ============================================================================
# TEST & VALIDATION
# ============================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)

    print("\n" + "="*50)
    print("RESPONSE GENERATOR - VALIDATION TEST")
    print("="*50 + "\n")

    # Mock tool results
    test_cases = [
        {
            "tool": "create_appointment",
            "result": {
                "success": True,
                "appointment": {
                    "code": "RNV2025120114"
                }
            },
            "expected_keywords": ["randevu", "kod", "RNV2025120114"]
        },
        {
            "tool": "get_customer_appointments",
            "result": {
                "success": True,
                "appointments": []
            },
            "expected_keywords": ["kayÄ±tlÄ±", "randevu", "bulunmuyor"]
        },
        {
            "tool": "check_availability",
            "result": {
                "success": True,
                "available": False
            },
            "expected_keywords": ["dolu", "mÃ¼sait deÄŸil"]
        }
    ]

    print("Mock test cases prepared.")
    print("(Actual LLM test requires Gemini API key)")
    print("\n" + "="*50)
