"""
Response Generator - LLM Call #2
Tool sonuÃ§larÄ±nÄ± natural Turkish response'a Ã§evir
Temperature: 0.7 (Natural but consistent)
"""

import google.generativeai as genai
import logging
import json
from typing import Dict, Any, Optional


class ResponseGenerator:
    """
    LLM Call #2: Tool result â†’ Natural language response

    GÃ¶revler:
    1. Tool sonuÃ§larÄ±nÄ± yorumla
    2. Context-aware yanÄ±t Ã¼ret (customer name, campaigns)
    3. DoÄŸal, sÄ±cak, profesyonel ton
    4. KÄ±sa ve Ã¶z (max 2-3 cÃ¼mle)
    5. Emoji yok!

    KullanÄ±lan: Gemini text generation (NO function calling)
    """

    def __init__(self, gemini_model: genai.GenerativeModel):
        """
        Args:
            gemini_model: Gemini model instance
        """
        self.model = gemini_model
        self.logger = logging.getLogger(__name__)

    async def generate(
        self,
        action: Dict[str, Any],
        tool_result: Optional[Dict[str, Any]],
        context: Dict[str, Any]
    ) -> str:
        """
        Tool result ve action'a gÃ¶re natural response Ã¼ret.

        Args:
            action: FlowManager'dan gelen action
            tool_result: Tool execution sonucu (None olabilir)
            context: KonuÅŸma context'i (customer_name, campaigns, vb.)

        Returns:
            Natural Turkish response string
        """
        self.logger.info(f"ğŸ’¬ [LLM #2] Response generation baÅŸladÄ±")

        action_type = action.get("action")

        # EÄŸer action "ask_missing" veya "confirm" ise, LLM'e gitmeye gerek yok
        # FlowManager zaten message hazÄ±rlamÄ±ÅŸ
        if action_type in ["ask_missing", "confirm", "ask_alternative"]:
            response = action.get("message", "AnlayamadÄ±m, tekrar eder misiniz?")
            self.logger.info(f"âœ… [LLM #2] Direct message (no LLM): {response[:50]}...")
            return response

        # EÄŸer tool result varsa, LLM ile yorumla
        if tool_result and action_type == "tool_call":
            return await self._generate_tool_response(
                tool_name=action.get("tool"),
                tool_result=tool_result,
                context=context
            )

        # Chat mode - genel sohbet
        if action_type == "chat":
            return "BaÅŸka bir konuda yardÄ±mcÄ± olabilir miyim?"

        # Fallback
        return "AnlayamadÄ±m, tekrar eder misiniz?"

    def _clean_tool_result(self, tool_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Tool result'Ä± temizle - Gemini'ye gÃ¶ndermeden Ã¶nce.

        Traceback, stack trace, teknik hata mesajlarÄ±nÄ± kÄ±sa Ã¶zet haline getir.
        """
        if not isinstance(tool_result, dict):
            return {"success": False, "error": "Invalid tool result"}

        cleaned = {}

        for key, value in tool_result.items():
            # Error mesajlarÄ±nÄ± temizle
            if key == "error" and isinstance(value, str):
                # Traceback varsa sadece ilk satÄ±rÄ±nÄ± al
                if "Traceback" in value or "File " in value:
                    # Sadece hata tipini ve mesajÄ±nÄ± al
                    lines = value.split("\n")
                    error_line = lines[-1] if lines else value
                    # RuntimeError, ConnectionError gibi bilgiler yeterli
                    if ":" in error_line:
                        cleaned[key] = error_line.split(":", 1)[-1].strip()
                    else:
                        cleaned[key] = "Connection failed"
                else:
                    # Uzun hata mesajÄ±nÄ± kÄ±salt (max 100 karakter)
                    cleaned[key] = value[:100] if len(value) > 100 else value
            else:
                cleaned[key] = value

        return cleaned

    def _get_fallback_response(self, tool_name: str, tool_result: Dict[str, Any]) -> str:
        """
        LLM hata verdiÄŸinde tool-specific fallback mesaj dÃ¶ndÃ¼r.

        Bu, Gemini'nin safety filter'Ä±na takÄ±ldÄ±ÄŸÄ±nda veya boÅŸ yanÄ±t dÃ¶ndÃ¼ÄŸÃ¼nde devreye girer.
        """
        success = tool_result.get("success", False)

        # Tool-specific fallback messages
        fallback_messages = {
            "check_customer": {
                True: "MÃ¼ÅŸteri bilgileriniz bulundu. Devam edebiliriz.",
                False: "Telefon numaranÄ±zÄ± sistemde bulamadÄ±m. Yeni kayÄ±t oluÅŸturabiliriz."
            },
            "create_appointment": {
                True: f"Randevunuz oluÅŸturuldu. {tool_result.get('appointment', {}).get('code', '')}",
                False: "Randevu oluÅŸturulurken bir sorun oluÅŸtu. LÃ¼tfen tekrar deneyin."
            },
            "cancel_appointment": {
                True: "Randevunuz iptal edildi.",
                False: "Randevu iptal edilirken bir sorun oluÅŸtu."
            },
            "get_customer_appointments": {
                True: "Randevu bilgileriniz bulundu." if tool_result.get("appointments") else "KayÄ±tlÄ± randevunuz bulunmuyor.",
                False: "RandevularÄ±nÄ±z sorgulanÄ±rken bir sorun oluÅŸtu."
            },
            "check_availability": {
                True: "MÃ¼saitlik durumu kontrol edildi.",
                False: "MÃ¼saitlik kontrol edilirken bir sorun oluÅŸtu."
            },
            "list_experts": {
                True: "Uzman listesi hazÄ±r.",
                False: "Uzmanlar listelenirken bir sorun oluÅŸtu."
            },
            "list_services": {
                True: "Hizmet listesi hazÄ±r.",
                False: "Hizmetler listelenirken bir sorun oluÅŸtu."
            },
            "check_campaigns": {
                True: "Kampanya bilgileri hazÄ±r.",
                False: "Kampanyalar kontrol edilirken bir sorun oluÅŸtu."
            }
        }

        # Get fallback message
        tool_fallbacks = fallback_messages.get(tool_name, {
            True: "Ä°ÅŸleminiz tamamlandÄ±.",
            False: "ÃœzgÃ¼nÃ¼m, bir sorun oluÅŸtu. LÃ¼tfen tekrar deneyin."
        })

        return tool_fallbacks.get(success, "Ä°ÅŸleminiz tamamlandÄ±.")

    async def _generate_tool_response(
        self,
        tool_name: str,
        tool_result: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """
        Tool sonucunu LLM ile natural language'e Ã§evir.

        Args:
            tool_name: Ã‡aÄŸrÄ±lan tool'un adÄ±
            tool_result: Tool'dan dÃ¶nen sonuÃ§
            context: Customer name, campaigns, vb.

        Returns:
            Natural Turkish response
        """
        # Context'ten bilgileri al
        customer_name = context.get("customer_name", "MÃ¼ÅŸteri")
        active_campaigns = context.get("active_campaigns", [])

        # Prompt oluÅŸtur - COMPACT
        prompt = self._build_response_prompt(
            tool_name=tool_name,
            tool_result=tool_result,
            customer_name=customer_name,
            active_campaigns=active_campaigns
        )

        try:
            # Gemini'ye gÃ¶nder (text generation, temperature=0.7)
            response = self.model.generate_content(prompt)

            # GÃ¼venlik filtresi veya boÅŸ yanÄ±t kontrolÃ¼
            if not response.candidates:
                self.logger.warning("âš ï¸ [LLM #2] No candidates in response (safety filter?)")
                raise ValueError("No candidates in response")

            candidate = response.candidates[0]

            # finish_reason kontrolÃ¼ (2 = SAFETY, 3 = RECITATION)
            if hasattr(candidate, 'finish_reason') and candidate.finish_reason in [2, 3]:
                self.logger.warning(f"âš ï¸ [LLM #2] Response blocked (finish_reason={candidate.finish_reason})")
                raise ValueError(f"Response blocked by safety filter (reason={candidate.finish_reason})")

            # Text extraction
            response_text = response.text.strip()

            # Validation - JSON dÃ¶ndÃ¼rmÃ¼ÅŸ mÃ¼? (hata)
            if response_text.startswith("{") or response_text.startswith("["):
                self.logger.warning("âš ï¸ [LLM #2] LLM returned JSON instead of text")
                # JSON parse et ve iÃ§inden text'i Ã§Ä±kar
                try:
                    parsed = json.loads(response_text)
                    if isinstance(parsed, dict):
                        response_text = parsed.get("response", parsed.get("message", response_text))
                except:
                    pass

            # Max length check (300 karakter yeterli)
            if len(response_text) > 300:
                self.logger.warning(f"âš ï¸ [LLM #2] Response too long ({len(response_text)} chars)")
                response_text = response_text[:300] + "..."

            self.logger.info(f"âœ… [LLM #2] Generated response: {response_text[:50]}...")
            return response_text

        except ValueError as e:
            # Safety filter veya boÅŸ yanÄ±t hatasÄ±
            self.logger.error(f"âŒ [LLM #2] Safety/Empty response error: {e}")
            # Tool-specific fallback
            return self._get_fallback_response(tool_name, tool_result)

        except Exception as e:
            self.logger.error(f"âŒ [LLM #2] Generation error: {e}", exc_info=True)
            # Tool-specific fallback
            return self._get_fallback_response(tool_name, tool_result)

    def _build_response_prompt(
        self,
        tool_name: str,
        tool_result: Dict[str, Any],
        customer_name: str,
        active_campaigns: list
    ) -> str:
        """
        Response generation iÃ§in compact prompt.

        Stratejiler:
        - Tool-specific rules
        - Examples vermiyoruz (model iyi)
        - Max 30 satÄ±r
        - Hata mesajlarÄ±nÄ± temizle (Traceback'leri gÃ¶sterme)
        """
        # Tool result'Ä± temizle ve formatla
        cleaned_result = self._clean_tool_result(tool_result)
        tool_result_str = json.dumps(cleaned_result, ensure_ascii=False, indent=2)

        # Kampanya bilgisi (varsa)
        campaign_str = ""
        if active_campaigns:
            campaign_str = "\n### AKTÄ°F KAMPANYALAR ###\n"
            for c in active_campaigns[:2]:  # Max 2 kampanya
                campaign_str += f"- {c.get('name')}: %{c.get('discount')} indirim\n"

        prompt = f"""### GÃ–REV ###
Tool sonucunu doÄŸal TÃ¼rkÃ§e yanÄ±ta Ã§evir.

### BAÄLAM ###
MÃ¼ÅŸteri AdÄ±: {customer_name}
{campaign_str}
### TOOL SONUCU ###
Tool: {tool_name}
Result:
{tool_result_str}

### YANIT KURALLARI ###
1. **Randevu OluÅŸturuldu**: 'success': true ve 'code' varsa â†’ "Randevunuz oluÅŸturuldu. Kod: [CODE]. Sizi bekliyoruz!"
2. **Randevu Sorgu**:
   - Appointments boÅŸ â†’ "KayÄ±tlÄ± randevunuz bulunmuyor."
   - Appointments var, status='confirmed' â†’ Tarih,1 saat, hizmet, uzman listele. Ä°PTAL edilmiÅŸ olanlarÄ± GÃ–STERME!
   - ASLA "iptal edilmiÅŸ" veya "cancelled" deme confirmed randevular iÃ§in!
3. **Alternatif Saatler**: Max 3 seÃ§enek, kÄ±sa liste. "5 AralÄ±k: 09:00, 11:30, 14:00 mÃ¼sait. Hangisi uygun?"
4. **MÃ¼saitlik**: Slots varsa kÄ±saca listele. "Sabah 09:00 ve 10:30 mÃ¼sait."
5. **Uzmanlar**: "Åu uzmanlarÄ±mÄ±z hizmet veriyor: [Ä°simler]. Hangisini tercih edersiniz?"
6. **Kampanyalar**: Varsa kÄ±saca bahset. "{customer_name} Bey/HanÄ±m, %20 indirim kampanyamÄ±z var."
7. **Hata**: 'success': false â†’ Ã–zÃ¼r dile, alternatif Ã¶ner veya eksik bilgi sor.
8. **Ton**: SÄ±cak, profesyonel. MÃ¼ÅŸteri adÄ±nÄ± kullan ("{customer_name} Bey/HanÄ±m").
9. **Uzunluk**: Max 2-3 cÃ¼mle. KÄ±sa ve Ã¶z.
10. **EMOJÄ° YOK**: HiÃ§ emoji kullanma!

### Ã‡IKTI ###
Sadece doÄŸal TÃ¼rkÃ§e yanÄ±t yaz. JSON, kod, markup YOK!
"""
        return prompt


# ============================================================================
# TEST & VALIDATION
# ============================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)

    print("\n" + "="*50)
    print("RESPONSE GENERATOR - VALIDATION TEST")
    print("="*50 + "\n")

    # Mock tool results
    test_cases = [
        {
            "tool": "create_appointment",
            "result": {
                "success": True,
                "appointment": {
                    "code": "RNV2025120114"
                }
            },
            "expected_keywords": ["randevu", "kod", "RNV2025120114"]
        },
        {
            "tool": "get_customer_appointments",
            "result": {
                "success": True,
                "appointments": []
            },
            "expected_keywords": ["kayÄ±tlÄ±", "randevu", "bulunmuyor"]
        },
        {
            "tool": "check_availability",
            "result": {
                "success": True,
                "available": False
            },
            "expected_keywords": ["dolu", "mÃ¼sait deÄŸil"]
        }
    ]

    print("Mock test cases prepared.")
    print("(Actual LLM test requires Gemini API key)")
    print("\n" + "="*50)
